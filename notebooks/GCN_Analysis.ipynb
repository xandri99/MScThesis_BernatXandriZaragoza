{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, '..')\n",
    "from src import models, graph, coarsening, utils\n",
    "import sklearn.metrics\n",
    "import sklearn.neighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n",
    "import scipy.sparse.linalg\n",
    "import scipy.spatial.distance\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################\n",
    "#       IMPORTANT : due to confidentiality requeriments, the names of the files and directories\n",
    "#       have been changed. Thus, this code would not run unless these parameters are corrected.\n",
    "###############################################################################################################\n",
    "\n",
    "\n",
    "working_dir = os.getcwd()\n",
    "working_dir = working_dir.strip('GCNN_paper_adaptation')\n",
    "data_dir = working_dir + 'Thesis/data/PROTECTED_DATA/'\n",
    "\n",
    "\n",
    "## Load the datasets\n",
    "# Transcriptomics Data \n",
    "transcriptomics_TumorOnly_dir = data_dir + 'TPM_TumorOnly.csv'\n",
    "transcriptomics_dataset = pd.read_csv(transcriptomics_TumorOnly_dir, index_col=0)\n",
    "\n",
    "# Classification Tags\n",
    "labels_classification_dir = data_dir + 'Gender_Classification.csv'\n",
    "labels = pd.read_csv(labels_classification_dir, index_col=0)\n",
    "\n",
    "\n",
    "# Figures Saving output dir\n",
    "\n",
    "\n",
    "# Convert The directory to the name of the column\n",
    "trait_used_as_label = labels_classification_dir.replace(data_dir, '').replace('_Classification.csv', '')\n",
    "trait_used_as_label = re.sub(r'(?<=\\w)([A-Z])', r' \\1', trait_used_as_label) # Add spaces before the capital letters for formatting\n",
    "\n",
    "\n",
    "# Convert labels to categorical values\n",
    "class_values = labels[trait_used_as_label].astype('category').cat.codes\n",
    "labels['label'] = class_values\n",
    "\n",
    "# \"\"\"\n",
    "## Make a subset to save RAM\n",
    "subset_dataset_size = 400\n",
    "transcriptomics_dataset = transcriptomics_dataset.iloc[:, :subset_dataset_size] \n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing as per in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paper preprocessing (Super Agressive)\n",
    "\n",
    "###Important to notice than in the paper, they work with log2(FPKM + 1) and we have TPM\n",
    "# Applying log transformation to TPM data\n",
    "transcriptomics_log_transformed = np.log2(transcriptomics_dataset + 1)\n",
    "\n",
    "\n",
    "# thresholds as per the paper\n",
    "mean_threshold = 0.5\n",
    "std_dev_threshold = 0.8\n",
    "\n",
    "# Kepp only genes with mean expression>0.5 and standard deviation>0.8\n",
    "genes_mean_expression = transcriptomics_log_transformed.mean(axis=0)\n",
    "genes_std_deviation = transcriptomics_log_transformed.std(axis=0)\n",
    "transcriptomics_clean = transcriptomics_log_transformed.loc[:, (genes_mean_expression > mean_threshold) & (genes_std_deviation > std_dev_threshold)]\n",
    "\n",
    "# Print the number of genes removed\n",
    "num_genes_removed = transcriptomics_dataset.shape[1] - transcriptomics_clean.shape[1]\n",
    "print(\"Preprocessing removed\", str(num_genes_removed), \"genes\")\n",
    "print(\"We have\", str(transcriptomics_clean.shape[1]), \"genes left\")\n",
    "\n",
    "\n",
    "# Normalize gene expression between 0 and 1\n",
    "transcriptomics_normalized = (transcriptomics_clean - transcriptomics_clean.min()) / (transcriptomics_clean.max() - transcriptomics_clean.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessing used in all other methods, to test its effect in this method\n",
    "\n",
    "\n",
    "expression_th = 1.5\n",
    "\n",
    "# Filter out genes with low expression across all samples\n",
    "transcriptomics_normalized = transcriptomics_dataset.loc[:, (transcriptomics_dataset > expression_th).any(axis=0)].copy()\n",
    "\n",
    "# Apply log2 transformation to all values except for the first column (gene identifiers)\n",
    "transcriptomics_normalized.iloc[:, 1:] = np.log2(transcriptomics_normalized.iloc[:, 1:] + 1)\n",
    "\n",
    "# Data Standardization (Z-score normalization)\n",
    "transcriptomics_normalized.iloc[:, 1:] = transcriptomics_normalized.iloc[:, 1:].apply(scipy.stats.zscore, axis=0)\n",
    "\n",
    "\n",
    "# Print the number of genes removed\n",
    "num_genes_removed = transcriptomics_dataset.shape[1] - transcriptomics_normalized.shape[1]\n",
    "print(\"Preprocessing removed\", str(num_genes_removed), \"genes\")\n",
    "print(\"We have\", str(transcriptomics_normalized.shape[1]), \"genes left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the binary Adjacency matrix as per the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build our own Adjacency matrix as per in the paper.\n",
    "\n",
    "# Calculate Spearman Correlation and p-values\n",
    "transcriptomics_np = transcriptomics_normalized.values\n",
    "correlations, pvalues = scipy.stats.spearmanr(transcriptomics_np)\n",
    "\n",
    "# Construct the Adjacency Matrix\n",
    "adjacency_matrix_np = (correlations > 0.6) & (pvalues < 0.05)\n",
    "adjacency_matrix_np = adjacency_matrix_np.astype(int)\n",
    "\n",
    "# In the paper, they remove self-links\n",
    "np.fill_diagonal(adjacency_matrix_np, 0)\n",
    "\n",
    "# Remove Isolated Genes - does not correlate with any other gene\n",
    "is_not_isolated = adjacency_matrix_np.sum(axis=1) > 0\n",
    "filtered_adjacency_matrix_np = adjacency_matrix_np[is_not_isolated, :][:, is_not_isolated]\n",
    "\n",
    "# Same data with different formatting\n",
    "transcriptomics_normalized_Adj = transcriptomics_normalized.loc[:, is_not_isolated]\n",
    "\n",
    "\n",
    "print(str(transcriptomics_normalized.shape[1]-filtered_adjacency_matrix_np.shape[0]), 'genes were removed as Isolated Genes')\n",
    "print(\"We have\", str(filtered_adjacency_matrix_np.shape[0]), \"genes left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the heatmaps using matplotlib\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Correlation Matrix Heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(correlations, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Filtered Adjacency Matrix Heatmap\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(filtered_adjacency_matrix_np, cmap='coolwarm')\n",
    "plt.colorbar()\n",
    "plt.title('Filtered Adjacency Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the genes selected for the analysis, for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_genes = transcriptomics_normalized_Adj.columns\n",
    "genes_left_df = pd.DataFrame(selected_genes, columns=['Gene Name'])\n",
    "\n",
    "# Save the gene names to a CSV file with one gene name per line\n",
    "genes_left_df.to_csv('selected_genes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Coarsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform into the specific formatting\n",
    "connections_indices = np.where(filtered_adjacency_matrix_np == 1)\n",
    "row = connections_indices[0].astype('float32')\n",
    "col = connections_indices[1].astype('float32')\n",
    "value = np.ones(len(col)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part of the original code\n",
    "coarsening_levels = 1\n",
    "\n",
    "A = scipy.sparse.coo_matrix((value, (row, col))) # Not enforcing shape\n",
    "graphs, perm = coarsening.coarsen(A, levels=coarsening_levels, self_connections=False)\n",
    "L = [graph.laplacian(A, normalized=True,renormalized=True) for A in graphs]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "\n",
    "# Shuffle samples\n",
    "transcriptomics_normalized_shuffled = transcriptomics_normalized_Adj.sample(frac=1, random_state=42)\n",
    "\n",
    "# Calculate the number of rows for each subset\n",
    "total_rows = transcriptomics_normalized_shuffled.shape[0]\n",
    "subset_1_rows = int(total_rows * train_split)\n",
    "\n",
    "# Make train, test transcriptomics datasets\n",
    "train_data = transcriptomics_normalized_shuffled.iloc[:subset_1_rows]\n",
    "test_data = transcriptomics_normalized_shuffled.iloc[subset_1_rows:]\n",
    "\n",
    "# Make train, test labels datasets\n",
    "train_label = labels.loc[train_data.index]\n",
    "test_label = labels.loc[test_data.index]\n",
    "\n",
    "# Turn everything into matrix\n",
    "train_data = train_data.values\n",
    "test_data = test_data.values\n",
    "train_label = train_label['label'].values.astype('float32')\n",
    "test_label = test_label['label'].values.astype('float32')\n",
    "\n",
    "# Make validation a copy of test, as in the paper\n",
    "val_data = test_data.copy()\n",
    "val_label = test_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original code from this point on\n",
    "Train_Data = coarsening.perm_data(train_data, perm[0])\n",
    "Test_Data = coarsening.perm_data(test_data, perm[0])\n",
    "Val_Data = coarsening.perm_data(val_data, perm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label_count = labels['label'].nunique()   # number of classes\n",
    "\n",
    "common = {}\n",
    "common['dir_name']       = 'test/'\n",
    "common['num_epochs']     = 100\n",
    "common['batch_size']     = 50\n",
    "common['decay_steps']    = 17.7 # * common['num_epochs'] since not used use as in momentum \n",
    "common['eval_frequency'] = 10 * common['num_epochs']\n",
    "common['brelu']          = 'b1relu'\n",
    "common['pool']           = 'apool1'\n",
    "\n",
    "model_perf = utils.model_perf()\n",
    "\n",
    "common['regularization'] = 0\n",
    "common['dropout']        = 1\n",
    "common['learning_rate']  = .001\n",
    "common['decay_rate']     = 0.95\n",
    "common['momentum']       = 0\n",
    "\n",
    "common['F']              = [1]\n",
    "common['K']              = [1]\n",
    "common['p']              = [2]\n",
    "common['M']              = [1024,unique_label_count]\n",
    "\n",
    "\n",
    "name = 'Run1'\n",
    "params = common.copy()\n",
    "params['dir_name'] += name\n",
    "\n",
    "params['filter'] = 'chebyshev2'\n",
    "params['brelu'] = 'b1relu'\n",
    "\n",
    "model_perf.test(models.cgcnn(L, **params), name, params, Train_Data, train_label, Val_Data, val_label, Test_Data, test_label)\n",
    "\n",
    "model_perf.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
